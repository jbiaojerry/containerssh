{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ContainerSSH: An SSH server that launches containers This is a Proof of Concept SSH server written in Go that sends any shell directly into a Docker container or Kubernetes pod instead of launching it on a local machine. It uses an HTTP microservice as an authentication endpoint for SSH connections. What is this? \u00b6 This is an SSH server that launches containers for every incoming connection . You can run it on the host or in a container. It needs two things: an authentication server and access to your container environment. Use cases \u00b6 Web hosting: Imagine user A has access to site X and Y, user B has access to site Y and Z. You can use ContainerSSH to mount the appropriate sites for the SSH session. Practicing environments: Launch dummy containers for practice environment. Honeypot: Let attackers into an enclosed environment and observe them. Security: Grant your developers on-demand access to environments with changing credentials. How does it work? \u00b6 +------+ +--------------+ 2. +-------------------+ | | | | -----> | Auth server | | | | | +-------------------+ | | | | | | 1. | | 3. +-------------------+ | User | -----> | ContainerSSH | -----> | Config server | | | | | +-------------------+ | | | | | | | | 4. +-------------------+ | | | | -----> | Container Backend | +------+ +--------------+ +-------------------+ The user opens an SSH connection to ContainerSSH. ContainerSSH calls the authentication server with the users username and password/pubkey to check if its valid. ContainerSSH calls the config server to obtain backend location and configuration (if configured) ContainerSSH calls the container backend to launch the container with the specified configuration. All input from the user is sent directly to the backend, output from the container is sent to the user. Curious? Learn more about how this works in my blog post.","title":"Home"},{"location":"#what-is-this","text":"This is an SSH server that launches containers for every incoming connection . You can run it on the host or in a container. It needs two things: an authentication server and access to your container environment.","title":"What is this?"},{"location":"#use-cases","text":"Web hosting: Imagine user A has access to site X and Y, user B has access to site Y and Z. You can use ContainerSSH to mount the appropriate sites for the SSH session. Practicing environments: Launch dummy containers for practice environment. Honeypot: Let attackers into an enclosed environment and observe them. Security: Grant your developers on-demand access to environments with changing credentials.","title":"Use cases"},{"location":"#how-does-it-work","text":"+------+ +--------------+ 2. +-------------------+ | | | | -----> | Auth server | | | | | +-------------------+ | | | | | | 1. | | 3. +-------------------+ | User | -----> | ContainerSSH | -----> | Config server | | | | | +-------------------+ | | | | | | | | 4. +-------------------+ | | | | -----> | Container Backend | +------+ +--------------+ +-------------------+ The user opens an SSH connection to ContainerSSH. ContainerSSH calls the authentication server with the users username and password/pubkey to check if its valid. ContainerSSH calls the config server to obtain backend location and configuration (if configured) ContainerSSH calls the container backend to launch the container with the specified configuration. All input from the user is sent directly to the backend, output from the container is sent to the user. Curious? Learn more about how this works in my blog post.","title":"How does it work?"},{"location":"authserver/","text":"Implementing an authentication server ContainerSSH does not know your users and their passwords. Therefore, it calls out to a microservice that you have to provide so it can verify the users, passwords and SSH keys. You will have to provide the microservice URL in the configuration. Note We have an OpenAPI document available for the authentication and configuration server. You can check the exact values available there, or use the OpenAPI document to generate parts of your server code. For password authentication ContainerSSH will call out to http://your-auth-server/password with the following request body. The password is base64 encoded to transfer special characters properly. { \"username\": \"username\", \"remoteAddress\": \"127.0.0.1:1234\", \"sessionId\": \"A base64 SSH session ID\", \"passwordBase64\": \"Base 64 password\" } Note: Earlier versions of ContainerSSH used the user field instead of username . While the user field still exists it is considered deprecated and will be removed in a future version. The public key auth ContainerSSH will call out to http://your-auth-server/pubkey in the following format. { \"username\": \"username\", \"remoteAddress\": \"127.0.0.1:1234\", \"sessionId\": \"A base64 SSH session ID\", \"publicKeyBase64\": \"Base 64 public key in SSH wire format\" } Note: Earlier versions of ContainerSSH used the user field instead of username . While the user field still exists it is considered deprecated and will be removed in a future version. The public key is provided in the SSH wire format in base64 encoding. Both endpoints need to respond with the following JSON: { \"success\": true } Tip You can find the source code for a test authentication and configuration server written in Go in the code repository","title":"Authentication Server"},{"location":"backends/","text":"Backend selection ContainerSSH is built to support multiple backends. The backend can be changed in the configuration file: # change to `kuberun` to talk to Kubernetes backend: dockerrun","title":"Selecting a Backend"},{"location":"configserver/","text":"Writing a configuration server ContainerSSH has the ability to configure the backend and the launched container dynamically based on the username and/or IP address. To do this ContainerSSH calls out to a configuration server if configured. You have the option to dynamically change the configuration based on the username by providing a config server URL: configserver: url: http://your-config-server-url/ Once you have this configured you can launch a HTTP server that returns a configuration fragment as described below on that address. Note We have an OpenAPI document available for the authentication and configuration server. You can check the exact values available there, or use the OpenAPI document to generate parts of your server code. The config server will receive a request in following format: { \"username\":\"ssh username\", \"sessionId\": \"ssh session ID\" } Your application will have to respond in the following format: { \"config\": { // Provide a partial configuration here } } You can view the full configuration structure in YAML format by running ./containerssh --dump-config . Note that your config server must respond in JSON format. Some configuration values cannot be overridden from the config server. These are the ones that get used before the connection is established, but the backends also override a few, such as attachstdio .","title":"Configuration Server"},{"location":"configuration/","text":"Configuring ContainerSSH Before you can run ContainerSSH you will need to create a configuration file. The minimal configuration file looks like this: ssh: hostkeys: # Generate a host key with ssh-keygen -t rsa - /path/to/your/host/key auth: # See auth server below url: http://your-auth-server/ password: true # Perform password authentication pubkey: false # Perform public key authentication The config file must end in .yml , .yaml , or .json . You can dump the entire configuration file using ./containerssh --dump-config Note Parts of the configuration can be provided dynamically based on the username using a configserver Note In order to actually use ContainerSSH you will also need to provide a backend configuration wither via this file or via the configserver .","title":"Configuration"},{"location":"dockerrun/","text":"The dockerrun backend The dockerrun backend launches a container using the Docker API Providing certificates \u00b6 Docker sockets allow connections over TCP with TLS encryption. You can provide these TLS certificates embedded in the YAML file in PEM format: dockerrun: host: tcp://127.0.0.1:2376 cacert: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- cert: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- key: | -----BEGIN RSA PRIVATE KEY----- ... -----END RSA PRIVATE KEY----- Changing the container image \u00b6 The container image depends on the backend you are using. For dockerrun you can change the image in the config file: dockerrun: config: container: image: your/image Detailed configuration \u00b6 The full configuration at the time of writing are as described below. Keep in mind that the configuration structure may change over time as they follow the Docker API . dockerrun: host: tcp://127.0.0.1:2375 cacert: \"\" cert: \"\" key: \"\" config: container: hostname: \"\" domainname: \"\" user: \"\" # The \"attach\" options are overridden and cannot be configured #attachstdin: false #attachstdout: false #attachstderr: false exposedports: {} # The \"tty\" option depends on the requested SSH mode and cannot be configured #tty: false # The \"stdin\" options are also configured by the backend #openstdin: false #stdinonce: false # Env can be configured but will be overridden by the values provided via SSH env: [] # CMD can be provided but will be overridden by the command sent via SSH cmd: [] healthcheck: null argsescaped: false image: janoszen/containerssh-image volumes: {} workingdir: \"\" entrypoint: [] networkdisabled: false macaddress: \"\" onbuild: [] labels: {} stopsignal: \"\" stoptimeout: null shell: [] host: binds: [] containeridfile: \"\" logconfig: type: \"\" config: {} networkmode: \"\" portbindings: {} restartpolicy: name: \"\" maximumretrycount: 0 autoremove: false volumedriver: \"\" volumesfrom: [] capadd: [] capdrop: [] dns: [] dnsoptions: [] dnssearch: [] extrahosts: [] groupadd: [] ipcmode: \"\" cgroup: \"\" links: [] oomscoreadj: 0 pidmode: \"\" privileged: false publishallports: false readonlyrootfs: false securityopt: [] storageopt: {} tmpfs: {} utsmode: \"\" usernsmode: \"\" shmsize: 0 sysctls: {} runtime: \"\" consolesize: - 0 - 0 isolation: \"\" resources: cpushares: 0 memory: 0 nanocpus: 0 cgroupparent: \"\" blkioweight: 0 blkioweightdevice: [] blkiodevicereadbps: [] blkiodevicewritebps: [] blkiodevicereadiops: [] blkiodevicewriteiops: [] cpuperiod: 0 cpuquota: 0 cpurealtimeperiod: 0 cpurealtimeruntime: 0 cpusetcpus: \"\" cpusetmems: \"\" devices: [] diskquota: 0 kernelmemory: 0 memoryreservation: 0 memoryswap: 0 memoryswappiness: null oomkilldisable: null pidslimit: 0 ulimits: [] cpucount: 0 cpupercent: 0 iomaximumiops: 0 iomaximumbandwidth: 0 mounts: [] init: null initpath: \"\" network: endpointsconfig: {} containername: \"\"","title":"The dockerrun Backend"},{"location":"dockerrun/#providing-certificates","text":"Docker sockets allow connections over TCP with TLS encryption. You can provide these TLS certificates embedded in the YAML file in PEM format: dockerrun: host: tcp://127.0.0.1:2376 cacert: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- cert: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- key: | -----BEGIN RSA PRIVATE KEY----- ... -----END RSA PRIVATE KEY-----","title":"Providing certificates"},{"location":"dockerrun/#changing-the-container-image","text":"The container image depends on the backend you are using. For dockerrun you can change the image in the config file: dockerrun: config: container: image: your/image","title":"Changing the container image"},{"location":"dockerrun/#detailed-configuration","text":"The full configuration at the time of writing are as described below. Keep in mind that the configuration structure may change over time as they follow the Docker API . dockerrun: host: tcp://127.0.0.1:2375 cacert: \"\" cert: \"\" key: \"\" config: container: hostname: \"\" domainname: \"\" user: \"\" # The \"attach\" options are overridden and cannot be configured #attachstdin: false #attachstdout: false #attachstderr: false exposedports: {} # The \"tty\" option depends on the requested SSH mode and cannot be configured #tty: false # The \"stdin\" options are also configured by the backend #openstdin: false #stdinonce: false # Env can be configured but will be overridden by the values provided via SSH env: [] # CMD can be provided but will be overridden by the command sent via SSH cmd: [] healthcheck: null argsescaped: false image: janoszen/containerssh-image volumes: {} workingdir: \"\" entrypoint: [] networkdisabled: false macaddress: \"\" onbuild: [] labels: {} stopsignal: \"\" stoptimeout: null shell: [] host: binds: [] containeridfile: \"\" logconfig: type: \"\" config: {} networkmode: \"\" portbindings: {} restartpolicy: name: \"\" maximumretrycount: 0 autoremove: false volumedriver: \"\" volumesfrom: [] capadd: [] capdrop: [] dns: [] dnsoptions: [] dnssearch: [] extrahosts: [] groupadd: [] ipcmode: \"\" cgroup: \"\" links: [] oomscoreadj: 0 pidmode: \"\" privileged: false publishallports: false readonlyrootfs: false securityopt: [] storageopt: {} tmpfs: {} utsmode: \"\" usernsmode: \"\" shmsize: 0 sysctls: {} runtime: \"\" consolesize: - 0 - 0 isolation: \"\" resources: cpushares: 0 memory: 0 nanocpus: 0 cgroupparent: \"\" blkioweight: 0 blkioweightdevice: [] blkiodevicereadbps: [] blkiodevicewritebps: [] blkiodevicereadiops: [] blkiodevicewriteiops: [] cpuperiod: 0 cpuquota: 0 cpurealtimeperiod: 0 cpurealtimeruntime: 0 cpusetcpus: \"\" cpusetmems: \"\" devices: [] diskquota: 0 kernelmemory: 0 memoryreservation: 0 memoryswap: 0 memoryswappiness: null oomkilldisable: null pidslimit: 0 ulimits: [] cpucount: 0 cpupercent: 0 iomaximumiops: 0 iomaximumbandwidth: 0 mounts: [] init: null initpath: \"\" network: endpointsconfig: {} containername: \"\"","title":"Detailed configuration"},{"location":"faq/","text":"FAQ Is ContainerSSH secure? \u00b6 ContainerSSH depends on a number of libraries to achieve what it does. A security hole in any of the critical ones could mean a compromise of your container environment, especially if you are using the dockerrun backend. (Docker has no access control so a compromise means your whole host is compromised.) Is ContainerSSH production-ready? \u00b6 No. ContainerSSH is very early in its development and has not undergone extensive testing yet. You should be careful before deploying it into production. Does ContainerSSH delete containers after it is done? \u00b6 ContainerSSH does its best to delete containers it creates. However, at this time there is no cleanup mechanism in case it crashes. Do I need to run ContainerSSH as root? \u00b6 No! In fact, you shouldn't! ContainerSSH is perfectly fine running as non-root as long as it has access to Kubernetes or Docker. (Granted, access to the Docker socket means it could easily launch a root process on the host.) Does ContainerSSH support SFTP? \u00b6 Yes, but your container image must contain an SFTP server binary and your config.yaml or config server must contain the correct path for the server. Does ContainerSSH support SCP? \u00b6 Not at this time. Does ContainerSSH support TCP port forwarding? \u00b6 Not at this time. TCP port forwarding is done outside of a channel. At this time ContainerSSH launches one container per SSH channel, so forwarding TCP ports would mean a complete overhaul of the entire architecture. In essence the architecture would be changed to launch one container per session, not per channel, and use exec to launch a shell or SFTP server for the channel. However, as you might imagine that's a bit of a larger change and will need quite a bit of work. Does ContainerSSH support SSH agent forwarding? \u00b6 Not at this time. SSH agent forwarding would require a separate binary agent within the container to proxy data. This is similar to how TCP port forwarding works, except that the authentication agent requests are sent on a per-channel basis. Additionally SSH agent forwarding is not documented well, it is proprietary to OpenSSH. (The request type is auth-agent-req@openssh.com .) Does ContainerSSH support X11 forwarding? \u00b6 Not at this time. X11 is sent over separate channels and would most probably need the overhaul that TCP port forwarding requires. As X11 forwarding isn't use much any more it is unlikely that ContainerSSH will ever support it. Does ContainerSSH support forwarding signals? \u00b6 Partially. The dockerrun backend supports it, the kuberun backend doesn't because Kubernetes itself doesn't. Does ContainerSSH support window resizing? \u00b6 Yes. Does ContainerSSH support environment variable passing? \u00b6 Yes. Does ContainerSSH support returning the exit status? \u00b6 Partially. The dockerrun backend supports it, the kuberun backend \u201cdoes its best\u201d but has some edge cases when the connection closes before the exit status can be obtained. Can ContainerSSH run exec into existing containers? \u00b6 Not at this time. The architecture needs to solidify before such a feature is implemented. Can ContainerSSH deploy additional services, such as sidecar containers, etc? \u00b6 ContainerSSH supports the entire Kubernetes pod specification so you can launch as many containers as you want in a single pod. The Docker backend, however, does not support sidecar containers. Can I add metadata to my pods with the kuberun backend? \u00b6 Not at this time. You may want to open up a feature request and detail your use case. Why is the kuberun backend so slow? \u00b6 Kubernetes is built for scale. That means there are some tradeoffs in terms of responsiveness. This is not something ContainerSSH can do anything about, it just takes a bit to launch a pod. You may want to fine-tune your Kubernetes cluster for responsiveness. Why is there no initial prompt with the kuberun backend? \u00b6 This is a known bug . Unfortunately the kuberun backend was built by reverse engineering kubectl as there is no documentation whatsoever on how the attach functionality works on pods. If you are good with Go you might want to help out here. Can I use my normal kubeconfig files? \u00b6 Unfortunately, no. Kubeconfig files are parsed by kubectl and the code is quite elaborate. At this time I don't think adding it to ContainerSSH is wise. Why does the kuberun backend have so many things it doesn't support? \u00b6 The kuberun backend was written by reverse engineering kubectl . Unfortunately the Kubernetes API is documented very poorly and is quirky in some places. Kubernetes is a very complex and fast moving beast so things like API documentation, a proper SDK and other niceties that make a developers life easy are not something that's currently available.","title":"FAQ"},{"location":"faq/#is-containerssh-secure","text":"ContainerSSH depends on a number of libraries to achieve what it does. A security hole in any of the critical ones could mean a compromise of your container environment, especially if you are using the dockerrun backend. (Docker has no access control so a compromise means your whole host is compromised.)","title":"Is ContainerSSH secure?"},{"location":"faq/#is-containerssh-production-ready","text":"No. ContainerSSH is very early in its development and has not undergone extensive testing yet. You should be careful before deploying it into production.","title":"Is ContainerSSH production-ready?"},{"location":"faq/#does-containerssh-delete-containers-after-it-is-done","text":"ContainerSSH does its best to delete containers it creates. However, at this time there is no cleanup mechanism in case it crashes.","title":"Does ContainerSSH delete containers after it is done?"},{"location":"faq/#do-i-need-to-run-containerssh-as-root","text":"No! In fact, you shouldn't! ContainerSSH is perfectly fine running as non-root as long as it has access to Kubernetes or Docker. (Granted, access to the Docker socket means it could easily launch a root process on the host.)","title":"Do I need to run ContainerSSH as root?"},{"location":"faq/#does-containerssh-support-sftp","text":"Yes, but your container image must contain an SFTP server binary and your config.yaml or config server must contain the correct path for the server.","title":"Does ContainerSSH support SFTP?"},{"location":"faq/#does-containerssh-support-scp","text":"Not at this time.","title":"Does ContainerSSH support SCP?"},{"location":"faq/#does-containerssh-support-tcp-port-forwarding","text":"Not at this time. TCP port forwarding is done outside of a channel. At this time ContainerSSH launches one container per SSH channel, so forwarding TCP ports would mean a complete overhaul of the entire architecture. In essence the architecture would be changed to launch one container per session, not per channel, and use exec to launch a shell or SFTP server for the channel. However, as you might imagine that's a bit of a larger change and will need quite a bit of work.","title":"Does ContainerSSH support TCP port forwarding?"},{"location":"faq/#does-containerssh-support-ssh-agent-forwarding","text":"Not at this time. SSH agent forwarding would require a separate binary agent within the container to proxy data. This is similar to how TCP port forwarding works, except that the authentication agent requests are sent on a per-channel basis. Additionally SSH agent forwarding is not documented well, it is proprietary to OpenSSH. (The request type is auth-agent-req@openssh.com .)","title":"Does ContainerSSH support SSH agent forwarding?"},{"location":"faq/#does-containerssh-support-x11-forwarding","text":"Not at this time. X11 is sent over separate channels and would most probably need the overhaul that TCP port forwarding requires. As X11 forwarding isn't use much any more it is unlikely that ContainerSSH will ever support it.","title":"Does ContainerSSH support X11 forwarding?"},{"location":"faq/#does-containerssh-support-forwarding-signals","text":"Partially. The dockerrun backend supports it, the kuberun backend doesn't because Kubernetes itself doesn't.","title":"Does ContainerSSH support forwarding signals?"},{"location":"faq/#does-containerssh-support-window-resizing","text":"Yes.","title":"Does ContainerSSH support window resizing?"},{"location":"faq/#does-containerssh-support-environment-variable-passing","text":"Yes.","title":"Does ContainerSSH support environment variable passing?"},{"location":"faq/#does-containerssh-support-returning-the-exit-status","text":"Partially. The dockerrun backend supports it, the kuberun backend \u201cdoes its best\u201d but has some edge cases when the connection closes before the exit status can be obtained.","title":"Does ContainerSSH support returning the exit status?"},{"location":"faq/#can-containerssh-run-exec-into-existing-containers","text":"Not at this time. The architecture needs to solidify before such a feature is implemented.","title":"Can ContainerSSH run exec into existing containers?"},{"location":"faq/#can-containerssh-deploy-additional-services-such-as-sidecar-containers-etc","text":"ContainerSSH supports the entire Kubernetes pod specification so you can launch as many containers as you want in a single pod. The Docker backend, however, does not support sidecar containers.","title":"Can ContainerSSH deploy additional services, such as sidecar containers, etc?"},{"location":"faq/#can-i-add-metadata-to-my-pods-with-the-kuberun-backend","text":"Not at this time. You may want to open up a feature request and detail your use case.","title":"Can I add metadata to my pods with the kuberun backend?"},{"location":"faq/#why-is-the-kuberun-backend-so-slow","text":"Kubernetes is built for scale. That means there are some tradeoffs in terms of responsiveness. This is not something ContainerSSH can do anything about, it just takes a bit to launch a pod. You may want to fine-tune your Kubernetes cluster for responsiveness.","title":"Why is the kuberun backend so slow?"},{"location":"faq/#why-is-there-no-initial-prompt-with-the-kuberun-backend","text":"This is a known bug . Unfortunately the kuberun backend was built by reverse engineering kubectl as there is no documentation whatsoever on how the attach functionality works on pods. If you are good with Go you might want to help out here.","title":"Why is there no initial prompt with the kuberun backend?"},{"location":"faq/#can-i-use-my-normal-kubeconfig-files","text":"Unfortunately, no. Kubeconfig files are parsed by kubectl and the code is quite elaborate. At this time I don't think adding it to ContainerSSH is wise.","title":"Can I use my normal kubeconfig files?"},{"location":"faq/#why-does-the-kuberun-backend-have-so-many-things-it-doesnt-support","text":"The kuberun backend was written by reverse engineering kubectl . Unfortunately the Kubernetes API is documented very poorly and is quirky in some places. Kubernetes is a very complex and fast moving beast so things like API documentation, a proper SDK and other niceties that make a developers life easy are not something that's currently available.","title":"Why does the kuberun backend have so many things it doesn't support?"},{"location":"hardening/","text":"Hardening ContainerSSH ContainerSSH is built to secure its inner workings as much as possible. You can take several steps to secure it further. Running ContainerSSH \u00b6 The default ContainerSSH image runs as a non-root user by default and exposes itself on port 2222. If you decide to build your own installation make sure ContainerSSH does not run as root as it is not required. Secure your Docker/Kubernetes \u00b6 Depending on which backend you are using you have to take different steps to secure it. When using Docker ContainerSSH will need access to the Docker socket. This undeniably means that ContainerSSH will be able to launch root processes on the host machine. You may want to look into running Docker in rootless mode or switching to Podman When running Kubernetes it is strongly advised that you deploy a pod security policy and a network policy. You should also make sure that ContainerSSH uses a restricted service account that can only access its own namespace. Securing your auth server \u00b6 Your authentication server contains all your secrets and is therefore a prime target. ContainerSSH delegates any and all access checking to the authentication server so you should make sure it prevents brute force attacks. Furthermore, you should make sure that the authentication server cannot be accessed from anywhere else. You can do this using firewalls, or alternatively you can configure ContainerSSH to use client certificates to authenticate itself: auth: url: http://127.0.0.1:8080 cacert: \"insert your expected CA certificate in PEM format here\" timeout: 2s cert: \"insert your client certificate in PEM format here\" key: \"insert your client key in PEM format here\" Securing your config server \u00b6 Similar to your authentication server you can also secure the config server in a similar manner: configserver: timeout: 2s url: http://127.0.0.1:8080/config cacert: \"insert your expected CA certificate in PEM format here\" cert: \"insert your client certificate in PEM format here\" key: \"insert your client key in PEM format here\"","title":"Hardening"},{"location":"hardening/#running-containerssh","text":"The default ContainerSSH image runs as a non-root user by default and exposes itself on port 2222. If you decide to build your own installation make sure ContainerSSH does not run as root as it is not required.","title":"Running ContainerSSH"},{"location":"hardening/#secure-your-dockerkubernetes","text":"Depending on which backend you are using you have to take different steps to secure it. When using Docker ContainerSSH will need access to the Docker socket. This undeniably means that ContainerSSH will be able to launch root processes on the host machine. You may want to look into running Docker in rootless mode or switching to Podman When running Kubernetes it is strongly advised that you deploy a pod security policy and a network policy. You should also make sure that ContainerSSH uses a restricted service account that can only access its own namespace.","title":"Secure your Docker/Kubernetes"},{"location":"hardening/#securing-your-auth-server","text":"Your authentication server contains all your secrets and is therefore a prime target. ContainerSSH delegates any and all access checking to the authentication server so you should make sure it prevents brute force attacks. Furthermore, you should make sure that the authentication server cannot be accessed from anywhere else. You can do this using firewalls, or alternatively you can configure ContainerSSH to use client certificates to authenticate itself: auth: url: http://127.0.0.1:8080 cacert: \"insert your expected CA certificate in PEM format here\" timeout: 2s cert: \"insert your client certificate in PEM format here\" key: \"insert your client key in PEM format here\"","title":"Securing your auth server"},{"location":"hardening/#securing-your-config-server","text":"Similar to your authentication server you can also secure the config server in a similar manner: configserver: timeout: 2s url: http://127.0.0.1:8080/config cacert: \"insert your expected CA certificate in PEM format here\" cert: \"insert your client certificate in PEM format here\" key: \"insert your client key in PEM format here\"","title":"Securing your config server"},{"location":"image/","text":"Building a container image for ContainerSSH ContainerSSH has no requirements as to the container image you are running apart from the fact that they need to be Linux containers. If you wish to use SFTP you have to add an SFTP server ( apt install openssh-sftp-server on Ubuntu) to the container image and configure the path of the SFTP server correctly in your config.yaml. The sample image janoszen/containerssh-image contains an SFTP server.","title":"Creating an Image"},{"location":"installation/","text":"Installing ContainerSSH ContainerSSH is provided on the GitHub releases page . The easiest way to install it is to run it in a container itself from the Docker hub . Depending on which backend you choose you may have to provide additional options. For a simple Docker example check out the quick start guide","title":"Installation"},{"location":"kuberun/","text":"The kuberun backend The kuberun backend runs a pod in a Kubernetes cluster and attaches to a container there. Running outside of Kubernetes \u00b6 If you are running ContainerSSH outside of Kubernetes you will need the following configuration: kuberun: connection: host: your-kubernetes-api-server:6443 cert: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- key: | -----BEGIN RSA PRIVATE KEY----- ... -----END RSA PRIVATE KEY----- cacert: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- Alternatively you can use cacertFile , keyFile and certFile to point to files on the filesystem. Running inside a Kubernetes cluster \u00b6 When you run inside of a Kubernetes cluster you can use the service account token: kuberun: connection: certFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token Changing the container image \u00b6 For the kuberun backend the container image can be changed by modifying the pod spec: kuberun: pod: namespace: default consoleContainerNumber: 0 podSpec: volumes: [] initcontainers: [] containers: - name: shell image: janoszen/containerssh-image Note: if you are running multiple containers you should specify the consoleContainerNumber parameter to indicate which container you wish to attach to when an SSH session is opened. Detailed configuration \u00b6 The full configuration looks as follows: kuberun: connection: host: kubernetes.docker.internal:6443 path: /api username: docker-desktop password: \"\" insecure: false serverName: \"\" certFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt keyFile: \"\" cacertFile: \"\" cert: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- key: | -----BEGIN RSA PRIVATE KEY----- ... -----END RSA PRIVATE KEY----- cacert: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- bearerToken: \"\" bearerTokenFile: \"\" qps: 5 burst: 10 timeout: 0s pod: namespace: default # If you have multiple containers which container should the SSH session attach to? consoleContainerNumber: 0 podSpec: volumes: [] initcontainers: [] containers: # The name doesn't matter - name: shell image: janoszen/containerssh-image # This may be overridden by the SSH client command: [] args: [] workingdir: \"\" ports: [] envfrom: [] # These will be populated from the SSH session but you can provide additional ones. env: [] resources: limits: {} requests: {} volumemounts: [] volumedevices: [] livenessprobe: null readinessprobe: null startupprobe: null lifecycle: null terminationmessagepath: \"\" terminationmessagepolicy: \"\" imagepullpolicy: \"\" securitycontext: null # These 3 will be overridden based on the SSH session #stdin: false #stdinonce: false #tty: false ephemeralcontainers: [] restartpolicy: \"\" terminationgraceperiodseconds: null activedeadlineseconds: null dnspolicy: \"\" nodeselector: {} serviceaccountname: \"\" deprecatedserviceaccount: \"\" automountserviceaccounttoken: null nodename: \"\" hostnetwork: false hostpid: false hostipc: false shareprocessnamespace: null securitycontext: null imagepullsecrets: [] hostname: \"\" subdomain: \"\" affinity: null schedulername: \"\" tolerations: [] hostaliases: [] priorityclassname: \"\" priority: null dnsconfig: null readinessgates: [] runtimeclassname: null enableservicelinks: null preemptionpolicy: null overhead: {} topologyspreadconstraints: [] subsystems: # This will be used as `command` when the client asks for the SFTP subsystem. sftp: /usr/lib/openssh/sftp-server timeout: 1m0s","title":"The kuberun Backend"},{"location":"kuberun/#running-outside-of-kubernetes","text":"If you are running ContainerSSH outside of Kubernetes you will need the following configuration: kuberun: connection: host: your-kubernetes-api-server:6443 cert: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- key: | -----BEGIN RSA PRIVATE KEY----- ... -----END RSA PRIVATE KEY----- cacert: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- Alternatively you can use cacertFile , keyFile and certFile to point to files on the filesystem.","title":"Running outside of Kubernetes"},{"location":"kuberun/#running-inside-a-kubernetes-cluster","text":"When you run inside of a Kubernetes cluster you can use the service account token: kuberun: connection: certFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token","title":"Running inside a Kubernetes cluster"},{"location":"kuberun/#changing-the-container-image","text":"For the kuberun backend the container image can be changed by modifying the pod spec: kuberun: pod: namespace: default consoleContainerNumber: 0 podSpec: volumes: [] initcontainers: [] containers: - name: shell image: janoszen/containerssh-image Note: if you are running multiple containers you should specify the consoleContainerNumber parameter to indicate which container you wish to attach to when an SSH session is opened.","title":"Changing the container image"},{"location":"kuberun/#detailed-configuration","text":"The full configuration looks as follows: kuberun: connection: host: kubernetes.docker.internal:6443 path: /api username: docker-desktop password: \"\" insecure: false serverName: \"\" certFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt keyFile: \"\" cacertFile: \"\" cert: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- key: | -----BEGIN RSA PRIVATE KEY----- ... -----END RSA PRIVATE KEY----- cacert: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- bearerToken: \"\" bearerTokenFile: \"\" qps: 5 burst: 10 timeout: 0s pod: namespace: default # If you have multiple containers which container should the SSH session attach to? consoleContainerNumber: 0 podSpec: volumes: [] initcontainers: [] containers: # The name doesn't matter - name: shell image: janoszen/containerssh-image # This may be overridden by the SSH client command: [] args: [] workingdir: \"\" ports: [] envfrom: [] # These will be populated from the SSH session but you can provide additional ones. env: [] resources: limits: {} requests: {} volumemounts: [] volumedevices: [] livenessprobe: null readinessprobe: null startupprobe: null lifecycle: null terminationmessagepath: \"\" terminationmessagepolicy: \"\" imagepullpolicy: \"\" securitycontext: null # These 3 will be overridden based on the SSH session #stdin: false #stdinonce: false #tty: false ephemeralcontainers: [] restartpolicy: \"\" terminationgraceperiodseconds: null activedeadlineseconds: null dnspolicy: \"\" nodeselector: {} serviceaccountname: \"\" deprecatedserviceaccount: \"\" automountserviceaccounttoken: null nodename: \"\" hostnetwork: false hostpid: false hostipc: false shareprocessnamespace: null securitycontext: null imagepullsecrets: [] hostname: \"\" subdomain: \"\" affinity: null schedulername: \"\" tolerations: [] hostaliases: [] priorityclassname: \"\" priority: null dnsconfig: null readinessgates: [] runtimeclassname: null enableservicelinks: null preemptionpolicy: null overhead: {} topologyspreadconstraints: [] subsystems: # This will be used as `command` when the client asks for the SFTP subsystem. sftp: /usr/lib/openssh/sftp-server timeout: 1m0s","title":"Detailed configuration"},{"location":"privacy/","text":"Privacy policy \u00b6 This is the privacy policy for the website projects.pasztor.at/containerssh. Cookies \u00b6 This website uses no cookies. Personal data collected by this website \u00b6 This website does not directly collect personal data. Third party providers \u00b6 This website is hosted on GitHub pages. As such, when loading this website, your IP address will be available and may be stored by GitHub in their accesslogs, along with the information which page specifically you loaded.","title":"Privacy Policy"},{"location":"privacy/#privacy-policy","text":"This is the privacy policy for the website projects.pasztor.at/containerssh.","title":"Privacy policy"},{"location":"privacy/#cookies","text":"This website uses no cookies.","title":"Cookies"},{"location":"privacy/#personal-data-collected-by-this-website","text":"This website does not directly collect personal data.","title":"Personal data collected by this website"},{"location":"privacy/#third-party-providers","text":"This website is hosted on GitHub pages. As such, when loading this website, your IP address will be available and may be stored by GitHub in their accesslogs, along with the information which page specifically you loaded.","title":"Third party providers"},{"location":"quickstart/","text":"Quick start This is a quick start guide to get a test server up and running in less than 5 minutes with docker-compose . Step 1: Set up a Dockerized environment \u00b6 To run this quick start please make sure you have a working Docker environment and a working docker-compose . Step 2: download the sample files \u00b6 Please download the contents of the example directory from the source code repository. Step 3: Launch ContainerSSH \u00b6 In the downloaded directory run docker-compose build and then docker-compose up . Step 4: Logging in \u00b6 Run ssh foo@localhost -p 2222 on the same machine. You should be able to log in with any password. Alternatively you can also try the user busybox to land in a Busybox container. Step 5: Making it productive \u00b6 The authentication and configuration server included in the example is a dummy server and lets any password in. To actually use ContainerSSH you will have to write your own authentication server and you may want to write your own configuration server too .","title":"Quick Start"},{"location":"quickstart/#step-1-set-up-a-dockerized-environment","text":"To run this quick start please make sure you have a working Docker environment and a working docker-compose .","title":"Step 1: Set up a Dockerized environment"},{"location":"quickstart/#step-2-download-the-sample-files","text":"Please download the contents of the example directory from the source code repository.","title":"Step 2: download the sample files"},{"location":"quickstart/#step-3-launch-containerssh","text":"In the downloaded directory run docker-compose build and then docker-compose up .","title":"Step 3: Launch ContainerSSH"},{"location":"quickstart/#step-4-logging-in","text":"Run ssh foo@localhost -p 2222 on the same machine. You should be able to log in with any password. Alternatively you can also try the user busybox to land in a Busybox container.","title":"Step 4: Logging in"},{"location":"quickstart/#step-5-making-it-productive","text":"The authentication and configuration server included in the example is a dummy server and lets any password in. To actually use ContainerSSH you will have to write your own authentication server and you may want to write your own configuration server too .","title":"Step 5: Making it productive"}]}